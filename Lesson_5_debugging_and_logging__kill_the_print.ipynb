{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logging and Debugging\n",
    "\n",
    "This lesson will deal on how to make sure that our code is doing what is supposed to be doing.\n",
    "\n",
    "This is related to testing, but can be viewed as complementary to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will discuss:\n",
    "\n",
    "* debugging\n",
    "* assertions\n",
    "* logging\n",
    "\n",
    "and, given time:\n",
    "\n",
    "* linters\n",
    "* type checkers\n",
    "* warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All these tools help us ensure that the program is doing what is supposed to be doing.\n",
    "\n",
    "While tests check that the program logic is correct, these tools helps you check that the program is implementing the operations you think it's doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### the logic\n",
    "\n",
    "most of these techniques are necessary to help you understand what you program is *actually* doing, instead of what you think it is supposed to be doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Debugging\n",
    "\n",
    "A debugger is a program that attach itself to yours and monitor it state and allow you to control the execution in real time.\n",
    "\n",
    "It doesn't sound that crazy for python, but consider that the original debuggers were doing it for C programs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What we do when we execute our programs one line at the time from an editor like spyder is basically a manual for of a debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Python and IPython comes with a basic debugger for the command line, but most programs provide you with more advanced (and easy to use ones).\n",
    "\n",
    "We will discuss the basic ones, but (as usual) just to explain the basic concepts that they use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The basic operations can be divided in two main categories: \n",
    "\n",
    "* managing the execution\n",
    "* examine and modify the program state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **l**(list)\tLists the code at the current position\n",
    "* **u**(p)\tWalk up the call stack\n",
    "* **d**(own)\tWalk down the call stack\n",
    "* **n**(ext)\tExecute the next line (does not go down in new functions)\n",
    "* **s**(tep)\tExecute the next statement (goes down in new functions)\n",
    "* **bt**\tPrint the call stack\n",
    "* **a**\tPrint the local variables\n",
    "* !command\tExecute the given Python command (by opposition to pdb commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **h**(elp)\tShow a list of commands, or find help on a specific command\n",
    "* **q**(uit)\tQuit the debugger and the program\n",
    "* **c**(ontinue)\tQuit the debugger, continue in the program\n",
    "* `<Return>`\tRepeat the previous command\n",
    "* **p**(rint)\tPrint variables\n",
    "* **s**(tep)\tStep into a subroutine\n",
    "* **r**(eturn)\tReturn out of a subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "dati = [1, 2, 3, 4]\n",
    "\n",
    "def my_function():\n",
    "    for dato in dati:\n",
    "        print(dati[dato])\n",
    "        \n",
    "my_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdati\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdato\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36mmy_function\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdato\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdati\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdati\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdato\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%run test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n",
      "> /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py(2)<module>()\n",
      "      1 \n",
      "----> 2 dati = [1, 2, 3, 4]\n",
      "      3 \n",
      "      4 def my_function():\n",
      "      5     for dato in dati:\n",
      "\n",
      "ipdb> n\n",
      "> /home/enrico/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py(4)<module>()\n",
      "      2 dati = [1, 2, 3, 4]\n",
      "      3 \n",
      "----> 4 def my_function():\n",
      "      5     for dato in dati:\n",
      "      6         print(dati[dato])\n",
      "\n",
      "ipdb> !print(dati)\n",
      "[1, 2, 3, 4]\n",
      "ipdb> !dati[-1] = 3\n",
      "ipdb> !print(dati)\n",
      "[1, 2, 3, 3]\n",
      "ipdb> c\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "%run -d test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assertions\n",
    "\n",
    "they are useful to express your expectations about the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "I was not expecting that",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-54e203d14fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I was not expecting that\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: I was not expecting that"
     ]
    }
   ],
   "source": [
    "assert 1==0, \"I was not expecting that\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "but don't rely on it, as they can be removed from the execution by using the flag `-O` (Optimize) when calling the python interpreter.\n",
    "\n",
    "Also, let's be honest, it does have a terrible syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could use a better (albeit slower) assertion library, **grappa**, to help get better syntax and better error results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from grappa import should, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops! Something went wrong!\n",
      "\n",
      "  The following assertion was not satisfied\n",
      "    subject \"foo\" should be equal to \"bar\"\n",
      "\n",
      "  What we expected\n",
      "    a value that is equal to \"bar\"\n",
      "\n",
      "  What we got instead\n",
      "    an value of type \"str\" with data \"foo\"\n",
      "\n",
      "  Difference comparison\n",
      "    > - foo\n",
      "    > + bar\n",
      "\n",
      "  Where\n",
      "    File \"<ipython-input-3-dd9644d0aacd>\", line 2, in <module>\n",
      "\n",
      "     1|   try:\n",
      "     2| >     'foo' | should.be.equal.to('bar')\n",
      "     3|   except AssertionError as e:\n",
      "     4|       print(e)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    'foo' | should.be.equal.to('bar')\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with should({'foo': 'bar'}):\n",
    "    should.be.a(dict)\n",
    "    should.have.length(1)\n",
    "    should.have.key('foo').that.should.be.equal.to('bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops! Something went wrong!\n",
      "\n",
      "  The following assertion was not satisfied\n",
      "    subject \"hello\" should be empty\n",
      "\n",
      "  What we expected\n",
      "    a value that is not \"None\" and its length is higher than zero\n",
      "\n",
      "  What we got instead\n",
      "    an object with type \"str\" which its length cannot be measured\n",
      "\n",
      "  Information\n",
      "    > An empty object can be \"None\", \"0\" or \"len(x) == 0\".\n",
      "      Most objects in Python can be tested via \"len(x)\"\n",
      "      such as str, list, tuple, dict, generator...\n",
      "      as well as any object that implements \"__len__()\" method.\n",
      "      => Reference: https://docs.python.org/3/library/functions.html#len\n",
      "\n",
      "  Where\n",
      "    File \"<ipython-input-29-fac7d0be13c0>\", line 2, in <module>\n",
      "\n",
      "     1|   try:\n",
      "     2| >     'hello' | should.be.empty\n",
      "     3|   except AssertionError as e:\n",
      "     4|       print(e)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    'hello' | should.be.empty\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops! Something went wrong!\n",
      "\n",
      "  The following assertion was not satisfied\n",
      "    subject \"hello\" expect to be a \"<class 'int'>\"\n",
      "\n",
      "  What we expected\n",
      "    an object that is a \"<class 'int'>\" type\n",
      "\n",
      "  What we got instead\n",
      "    an object of type \"str\" with value \"hello\"\n",
      "\n",
      "  Difference comparison\n",
      "    > - hello\n",
      "    > + <class 'int'>\n",
      "\n",
      "  Where\n",
      "    File \"<ipython-input-33-26e9dc31d426>\", line 3, in <module>\n",
      "\n",
      "     1|   data = 'hello'\n",
      "     2|   try:\n",
      "     3| >     expect(data).to.be.a('int')\n",
      "     4|   except AssertionError as e:\n",
      "     5|       print(e)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = 'hello'\n",
    "try:\n",
    "    expect(data).to.be.a('int')\n",
    "except AssertionError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logging\n",
    "\n",
    "When you execute your code and print the internal state of the program to check that is working properly, that is a rudimentary form of logging.\n",
    "\n",
    "Printing the state of your program works fine as long as your program is simple and the amount of state is small.\n",
    "\n",
    "For anything more complicated, you need to use a logging system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The basic idea of a logging system is to standardize how and what gets written on a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "from eliot import start_action, to_file, Message\n",
    "to_file(open(\"test.log\", \"w\"))\n",
    "\n",
    "def myfunction(value):\n",
    "    with start_action(action_type='myfunction', value=value):\n",
    "        return 1/value\n",
    "\n",
    "for number in [4, 1, 0, 2, 4]:\n",
    "    with start_action(action_type=\"start evaluation\", number=number):\n",
    "        point = number *2\n",
    "        total = sum(i for i in range(point))\n",
    "        with start_action(action_type=\"inside evaluation\", total=total):\n",
    "            result = myfunction(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstart_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inside evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36mmyfunction\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmyfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstart_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'myfunction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "!rm test.log\n",
    "%run test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc135185-26bb-44f4-adbf-93a762eca2f3\n",
      "└── start evaluation/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.003s\n",
      "    ├── number: 4\n",
      "    ├── inside evaluation/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.002s\n",
      "    │   ├── total: 28\n",
      "    │   ├── myfunction/2/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.001s\n",
      "    │   │   ├── value: 28\n",
      "    │   │   └── myfunction/2/2/2 ⇒ succeeded 2018-09-03 09:03:04\n",
      "    │   └── inside evaluation/2/3 ⇒ succeeded 2018-09-03 09:03:04\n",
      "    └── start evaluation/3 ⇒ succeeded 2018-09-03 09:03:04\n",
      "\n",
      "75834879-b121-40f8-97ef-04e27bbc6d61\n",
      "└── start evaluation/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.002s\n",
      "    ├── number: 1\n",
      "    ├── inside evaluation/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.001s\n",
      "    │   ├── total: 1\n",
      "    │   ├── myfunction/2/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.000s\n",
      "    │   │   ├── value: 1\n",
      "    │   │   └── myfunction/2/2/2 ⇒ succeeded 2018-09-03 09:03:04\n",
      "    │   └── inside evaluation/2/3 ⇒ succeeded 2018-09-03 09:03:04\n",
      "    └── start evaluation/3 ⇒ succeeded 2018-09-03 09:03:04\n",
      "\n",
      "e9c68561-2e34-4547-9b08-bade663468cb\n",
      "└── start evaluation/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.002s\n",
      "    ├── number: 0\n",
      "    ├── inside evaluation/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.001s\n",
      "    │   ├── total: 0\n",
      "    │   ├── myfunction/2/2/1 ⇒ started 2018-09-03 09:03:04 ⧖ 0.000s\n",
      "    │   │   ├── value: 0\n",
      "    │   │   └── myfunction/2/2/2 ⇒ failed 2018-09-03 09:03:04\n",
      "    │   │       ├── exception: builtins.ZeroDivisionError\n",
      "    │   │       └── reason: division by zero\n",
      "    │   └── inside evaluation/2/3 ⇒ failed 2018-09-03 09:03:04\n",
      "    │       ├── exception: builtins.ZeroDivisionError\n",
      "    │       └── reason: division by zero\n",
      "    └── start evaluation/3 ⇒ failed 2018-09-03 09:03:04\n",
      "        ├── exception: builtins.ZeroDivisionError\n",
      "        └── reason: division by zero\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!eliot-tree test.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"action_type\": \"start evaluation\", \"task_level\": [1], \"timestamp\": 1535965154.3335845, \"task_uuid\": \"409f42e6-0c10-4f59-b882-e4fb7f112241\", \"action_status\": \"started\", \"number\": 4}\r\n",
      "{\"action_type\": \"inside evaluation\", \"task_level\": [2, 1], \"timestamp\": 1535965154.333918, \"task_uuid\": \"409f42e6-0c10-4f59-b882-e4fb7f112241\", \"action_status\": \"started\", \"total\": 28}\r\n",
      "{\"task_uuid\": \"409f42e6-0c10-4f59-b882-e4fb7f112241\", \"timestamp\": 1535965154.3341036, \"action_type\": \"inside evaluation\", \"task_level\": [2, 2], \"action_status\": \"succeeded\"}\r\n",
      "{\"task_uuid\": \"409f42e6-0c10-4f59-b882-e4fb7f112241\", \"timestamp\": 1535965154.3342803, \"action_type\": \"start evaluation\", \"task_level\": [3], \"action_status\": \"succeeded\"}\r\n",
      "{\"action_type\": \"start evaluation\", \"task_level\": [1], \"timestamp\": 1535965154.334487, \"task_uuid\": \"3d429872-a765-4c18-9559-cc41c68be49f\", \"action_status\": \"started\", \"number\": 1}\r\n",
      "{\"action_type\": \"inside evaluation\", \"task_level\": [2, 1], \"timestamp\": 1535965154.3346956, \"task_uuid\": \"3d429872-a765-4c18-9559-cc41c68be49f\", \"action_status\": \"started\", \"total\": 1}\r\n",
      "{\"task_uuid\": \"3d429872-a765-4c18-9559-cc41c68be49f\", \"timestamp\": 1535965154.3348691, \"action_type\": \"inside evaluation\", \"task_level\": [2, 2], \"action_status\": \"succeeded\"}\r\n",
      "{\"task_uuid\": \"3d429872-a765-4c18-9559-cc41c68be49f\", \"timestamp\": 1535965154.3350365, \"action_type\": \"start evaluation\", \"task_level\": [3], \"action_status\": \"succeeded\"}\r\n",
      "{\"action_type\": \"start evaluation\", \"task_level\": [1], \"timestamp\": 1535965154.335238, \"task_uuid\": \"7738a51b-a796-478a-8e0a-6b8aad139034\", \"action_status\": \"started\", \"number\": 0}\r\n",
      "{\"action_type\": \"inside evaluation\", \"task_level\": [2, 1], \"timestamp\": 1535965154.3354425, \"task_uuid\": \"7738a51b-a796-478a-8e0a-6b8aad139034\", \"action_status\": \"started\", \"total\": 0}\r\n"
     ]
    }
   ],
   "source": [
    "!head test.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if you want to see the results in real time?\n",
    "\n",
    "A better solution is to periodically refresh the result of `eliot-tree`, piping the tail of the log file in it:\n",
    "\n",
    "    tail -f test.log | eliot-tree\n",
    "    \n",
    "for example, if we make our program be slower (simulating a slow computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The only limitations are:\n",
    "\n",
    "* you have to interrupt the tail process manually\n",
    "* actions are written only when completed, so if you have very high level actions this will not print until they are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "import time\n",
    "from eliot import start_action, to_file, Message, start_task\n",
    "to_file(open(\"test.log\", \"w\"))\n",
    "\n",
    "def myfunction(value):\n",
    "    with start_action(action_type='myfunction', value=value):\n",
    "        time.sleep(5)\n",
    "        result = 1/value\n",
    "        Message.log(result=result)\n",
    "        return 1/value\n",
    "\n",
    "for number in [4, 1, 3, 5, 0, 2, 4]:\n",
    "    with start_action(action_type=\"start evaluation\", number=number):\n",
    "        point = number *2\n",
    "        total = sum(i for i in range(point))\n",
    "        with start_action(action_type=\"inside evaluation\", total=total):\n",
    "            result = myfunction(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstart_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inside evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/didattica/corso_programmazione_1819/programmingCourseDIFA/test.py\u001b[0m in \u001b[0;36mmyfunction\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstart_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'myfunction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "!rm test.log\n",
    "%run test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otherwise, if you are used to live in the matrix, you can watch the log file directly with:\n",
    "\n",
    "    tail -f test.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warning systems\n",
    "\n",
    "Warnings are a way to comunicate directly with the user and let them know that there is something fishy going on.\n",
    "\n",
    "While logging is something that is run consistently, warnings should appear only in some specific situations.\n",
    "\n",
    "A tipical case is to inform your user that one of the functions that is being used is going to be removed from the next version of your library and that they should use something different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: this is an old script, use a new one!\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.warn(\"this is an old script, use a new one!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "if you want to raise an error when you catch a warning, you can use a specific context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "UserWarning",
     "evalue": "there is a problem!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-15bf7a32a4ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"there is a problem!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m: there is a problem!"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "        warnings.simplefilter('error', category=Warning)\n",
    "        warnings.warn(\"there is a problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "on the opposite, you might want to silence certain warnings as you know what you're doing.\n",
    "\n",
    "SPOILER: you probably should not use this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore', category=Warning)\n",
    "        warnings.warn(\"there is a problem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linters\n",
    "\n",
    "Linters are programs that check your code for possible mistakes and errors before the execution.\n",
    "\n",
    "there are several of them, with various level of informations that they can gather.\n",
    "\n",
    "Most editors can be configured to run them in the background and show the resulting informations directly in the editor window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "examples of things that they will catch are:\n",
    "\n",
    "* variable definited but not used\n",
    "* overloading of existing functions\n",
    "* syntax errors\n",
    "\n",
    "and so on.\n",
    "\n",
    "They are extremely useful when working with a dynamic language such as python, as they provide some functionalities of the traditional compilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "some of these linters are:\n",
    "\n",
    "* pylint\n",
    "* pycodestyle (previously called pep8)\n",
    "* pyflakes\n",
    "* flake8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "def eleva(n):\n",
    "    return n**2\n",
    "\n",
    "dati = [1, 2, 3, 4]\n",
    "\n",
    "for dato in dati:\n",
    "    print(eleva(dati[dato]))\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************* Module test\r\n",
      "test.py:9:0: C0303: Trailing whitespace (trailing-whitespace)\r\n",
      "test.py:10:0: C0304: Final newline missing (missing-final-newline)\r\n",
      "test.py:1:0: C0111: Missing module docstring (missing-docstring)\r\n",
      "test.py:2:0: C0103: Argument name \"n\" doesn't conform to snake_case naming style (invalid-name)\r\n",
      "test.py:2:0: C0111: Missing function docstring (missing-docstring)\r\n",
      "test.py:5:0: C0103: Constant name \"dati\" doesn't conform to UPPER_CASE naming style (invalid-name)\r\n",
      "test.py:10:6: E0602: Undefined variable 'data' (undefined-variable)\r\n",
      "\r\n",
      "-------------------------------------------------------------------\r\n",
      "Your code has been rated at -8.33/10 (previous run: 0.00/10, -8.33)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pylint test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "obviously not all suggestions are equally relevant, but they can spot several **code smells** before you run a long simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Static type checking\n",
    "\n",
    "A specific type of linter are the static type checkers, that are made possible by new syntax from python 3.\n",
    "\n",
    "I will not get into the details of it, just the general idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python is a dynamic language, but is still strongly typed.\n",
    "One just don't have to declare the typed beforehand.\n",
    "\n",
    "What they introduced is the possibility to annotate the code to express expectations over the type of variables, arguments and functions.\n",
    "This does not have any effect on running the code, but allow type checkers (the most famous one is `mypy`) to assess if the code is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "for example, the following code have a lot of issues, but they migh not be immediately apparent just looking at it.\n",
    "\n",
    "If we don't put any typing information, mypy doesn't complain and doesn't do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "def eleva(n):\n",
    "    return n.upper()\n",
    "\n",
    "dati = [1, 2, 3, 4]\n",
    "\n",
    "for dato in dati:\n",
    "    print(eleva(dati[dato]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!mypy test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I can start introducing types informations and will find progressively more possible mistakes.\n",
    "\n",
    "types are specified with a colon (`:`) after the argument or variable, followed by the type object that it should have.\n",
    "\n",
    "for the return type, one can use an arrow `->`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "def eleva(n: str) -> str:\n",
    "    return n.upper()\n",
    "\n",
    "dati = [1, 2, 3, 4]\n",
    "\n",
    "for dato in dati:\n",
    "    print(1+eleva(dati[dato]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.py:8: error: Unsupported operand types for + (\"int\" and \"str\")\r\n",
      "test.py:8: error: Argument 1 to \"eleva\" has incompatible type \"int\"; expected \"str\"\r\n"
     ]
    }
   ],
   "source": [
    "!mypy test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I can specify more complex types using the library `typing`, that allows to specify very complex structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test.py\n"
     ]
    }
   ],
   "source": [
    "%%file test.py\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def eleva(n: str):\n",
    "    return n.upper()\n",
    "\n",
    "dati: List[str] = [1, 2, 3, 4]\n",
    "\n",
    "for dato in dati:\n",
    "    print(eleva(dati[dato]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.py:7: error: List item 0 has incompatible type \"int\"; expected \"str\"\r\n",
      "test.py:7: error: List item 1 has incompatible type \"int\"; expected \"str\"\r\n",
      "test.py:7: error: List item 2 has incompatible type \"int\"; expected \"str\"\r\n",
      "test.py:7: error: List item 3 has incompatible type \"int\"; expected \"str\"\r\n",
      "test.py:10: error: No overload variant of \"__getitem__\" of \"list\" matches argument type \"str\"\r\n",
      "test.py:10: note: Possible overload variants:\r\n",
      "test.py:10: note:     def __getitem__(self, int) -> str\r\n",
      "test.py:10: note:     def __getitem__(self, slice) -> List[str]\r\n"
     ]
    }
   ],
   "source": [
    "!mypy test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "this allows me to annotate only the code I **care about** without having to deal with typing everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "you can find more info about tye checking and how to use it on this blog posts:\n",
    "  \n",
    "#### a general overview of the type systems\n",
    "https://www.bernat.tech/the-state-of-type-hints-in-python/\n",
    "\n",
    "#### an in-depth discussion of how the type system works and how to use it\n",
    "* [S01E01](https://blog.daftcode.pl/first-steps-with-python-type-system-30e4296722af)\n",
    "* [S01E02](https://blog.daftcode.pl/next-steps-with-python-type-system-efc4df5251c9)\n",
    "* [S02E01](https://blog.daftcode.pl/csi-python-type-system-episode-1-1c2ee1f8047c)\n",
    "* [S02E02](https://blog.daftcode.pl/csi-python-type-system-episode-2-baf5168038c0)\n",
    "* [S02E03](https://blog.daftcode.pl/covariance-contravariance-and-invariance-the-ultimate-python-guide-8fabc0c24278)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
